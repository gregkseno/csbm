data:
  type: quantized_images # choices: "toy", "images", "quantized_images", "texts"
  dataset: afhq
  dim: 512
  latent_dim: 32
  num_categories: 1024
  num_timesteps: 100
  num_skip_steps: 1
  coupling_type: independent # choices: "independent", "prior"
model:
  hidden_dim: 256
  num_channels: 4
  num_layers: 18
  num_att_heads: 16
  dropout: 0
codec:
  ckpt_path: checkpoints/vqgan_afhq_f16_1024.ckpt
  config_path: configs/vqgan_afhq_f16_1024.yaml
prior:
  alpha: 0.005
  type: uniform # choices: "uniform", "gaussian", "centroid_gaussian", "von_mises"
  eps: 1e-6
train:
  batch_size: 32
  low_precision: false
  gradient_accumulation_steps: 1
  iterations: 20
  prior_iterations: 20
  inner_iterations: 20000
  use_mini_batch: false
  ce_loss_coeff: 0.001
  kl_loss_coeff: 1
  mse_loss_coeff: 0
  ema_decay: 0.999
  optimizer:
    lr: 0.0004
    betas: [0.95, 0.99]
  #   weight_decay: 4.5e-2
  # scheduler:
  #     factor: 0.5
  #     patience: 1000
  #     min_lr: 1.0e-6
  #     threshold: 1.0e-1
  #     threshold_mode: rel
  #     warmup_lr: 4.5e-4 # the lr to be touched after warmup
  #     warmup: 10000
eval:
  freq: 1000
  num_samples: 16
  num_trajectories: 4 # How many trajecotries
  num_translations: 2 # How many times sample trajecotry from single point
