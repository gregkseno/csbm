data:
  type: texts # choices: "toy", "images", "quantized_images", "texts"
  dataset: amazon
  dim: 55
  num_categories: 8192
  num_timesteps: 100
  num_skip_steps: 1
  coupling_type: independent # choices: "independent", "prior"
  train_test_split: null # does nothing for AmazonDataset
model:
  config:
    name: small
    type: ddit
    hidden_size: 768
    cond_dim: 128
    length: 1024
    n_blocks: 12
    n_heads: 12
    scale_by_sigma: True
    dropout: 0.1
    tie_word_embeddings: False
tokenizer:
  path: checkpoints/tokenizer_amazon.json
prior:
  alpha: 0.01
  type: uniform # choices: "uniform", "gaussian", "centroid_gaussian", "von_mises"
  eps: 1e-20
train:
  batch_size: 32
  low_precision: true
  gradient_accumulation_steps: 1
  iterations: 20
  prior_iterations: 20
  inner_iterations: 20000
  use_mini_batch: false
  ce_loss_coeff: 0.001
  kl_loss_coeff: 1
  mse_loss_coeff: 0
  ema_decay: 0.999
  optimizer:
    lr: 0.0004
    betas: [0.95, 0.99]
  #   weight_decay: 4.5e-2
  # scheduler:
  #     factor: 0.5
  #     patience: 1000
  #     min_lr: 1.0e-6
  #     threshold: 1.0e-1
  #     threshold_mode: rel
  #     warmup_lr: 4.5e-4 # the lr to be touched after warmup
  #     warmup: 10000
eval:
  freq: 1000
  num_samples: 32
  num_trajectories: 1 # Does not work for texts
  num_translations: 1 # Does not work for texts
